{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "034d5be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time \n",
    "import re\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "from selenium import webdriver \n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver import Chrome \n",
    "from selenium.webdriver.chrome.service import Service  \n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "bed4b5d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shubhangib\\AppData\\Local\\Temp\\ipykernel_804\\2608793959.py:3: DeprecationWarning: headless property is deprecated, instead use add_argument('--headless') or add_argument('--headless=new')\n",
      "  options.headless = True\n"
     ]
    }
   ],
   "source": [
    "# start by defining the options \n",
    "options = Options()\n",
    "options.headless = True\n",
    "options.add_argument('--log-level=3')\n",
    "driver = webdriver.Chrome(options = options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "a400f4fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Requesting to get the url\n",
    "url = \"https://www.canfinhomes.com/Branch-locator.aspx\" \n",
    "driver.get(url)\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "4a89a46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clicking on View All button to access data \n",
    "WebDriverWait(driver,5).until(EC.element_to_be_clickable((By.NAME,\"ctl00$ContentPlaceHolder1$Button3\"))).click()\n",
    "time.sleep(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ccf26f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping using BeautifulSoup\n",
    "html_text = driver.page_source\n",
    "soup = BeautifulSoup(html_text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "01dc4ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Empty list to collect all dataframes from within the loop\n",
    "dfs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "54e2c259",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Preventing data from getting truncated\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "# Main table has nested tables, seperate for each branch information\n",
    "for table in soup.find_all('table', id= 'ctl00_ContentPlaceHolder1_dg_branch'):\n",
    "    # Accessing all branch tables one by one\n",
    "    for subtable in table.find_all('table', {'class' : 'tabcontent1'}):\n",
    "        # Readinf and converting table dimensions to make it compatible to comvert into a dataframe\n",
    "        info = pd.read_html(str(subtable))\n",
    "        info = np.array(info)\n",
    "        df = pd.DataFrame(info.tolist(), columns = [\"Name\"])\n",
    "        df['Name'] = df['Name'].astype('str')\n",
    "        # Seperating columns into address and remaining details\n",
    "        df2 = df.replace(\", '\",'_', regex=True)\n",
    "        df2 = pd.DataFrame(df2)\n",
    "        df2[['Address', 'Details']] = df2.Name.str.split(\"_\", expand = True)\n",
    "        # Seperating column with remaining details into telephone and email\n",
    "        df2[['Telephone', 'Email']] = df2.Details.str.split(\"Email ID:\", expand = True)\n",
    "        # Cleaning and dropping unnecessary columns\n",
    "        df2['Address'] = df2['Address'].str[2:-1]\n",
    "        df2['Email'] = df2['Email'].str[:-12]\n",
    "        df3 = df2.drop([\"Name\", \"Details\"], axis = 1)\n",
    "        df3['sample'] = df3['Address'].replace(\" \",'', regex=True)\n",
    "        df3['pincode'] = re.findall('\\d+', str(df3['sample']))[-1]\n",
    "        df4 = df3.drop([\"sample\"], axis = 1)\n",
    "#         print(df4)\n",
    "        #Appending all dataframes one into one list\n",
    "        dfs.append(df4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "485516ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenating all dataframes one below the other to create final dataset\n",
    "appended_data = pd.concat(dfs).drop_duplicates().reset_index(drop=True)\n",
    "# print(appended_data)\n",
    "appended_data.to_excel(\"page1_results.xlsx\", index = False)\n",
    "\n",
    "######This code only collects results from first page. Working on getting remaining pages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6cdbeee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b311d5f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "7358a60a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# for table in soup.find_all('table', id= 'ctl00_ContentPlaceHolder1_dg_branch'):\n",
    "#     for tr in table.find_all('tr', {'class' : 'vergridfooter'}):\n",
    "#         for td in tr.find_all('td'):\n",
    "#             for a in td.find_all('a'):\n",
    "#                 print(a)\n",
    "#                 WebDriverWait(driver,15).until(EC.element_to_be_clickable((By.TAG_NAME,\"a\"))).click()\n",
    "# #                 time.sleep(15)\n",
    "# #                 pd.set_option('display.max_colwidth', None)\n",
    "# #                 for table in soup.find_all('table', id= 'ctl00_ContentPlaceHolder1_dg_branch'):\n",
    "# #                     for subtable in table.find_all('table', {'class' : 'tabcontent1'}):\n",
    "# #                         info = pd.read_html(str(subtable))\n",
    "# #                         info = np.array(info)\n",
    "# #                         df = pd.DataFrame(info.tolist(), columns = [\"Name\"])\n",
    "# #                         df['Name'] = df['Name'].astype('str')\n",
    "# #                         df2 = df.replace(\", '\",'_', regex=True)\n",
    "# #                         df2 = pd.DataFrame(df2)\n",
    "# #                         df2[['Address', 'Details']] = df2.Name.str.split(\"_\", expand = True)\n",
    "# #                         df2[['Telephone', 'Email']] = df2.Details.str.split(\"Email ID:\", expand = True)\n",
    "# #                         df2['Address'] = df2['Address'].str[2:-1]\n",
    "# #                         df2['Email'] = df2['Email'].str[:-12]\n",
    "# #                         df3 = df2.drop([\"Name\", \"Details\"], axis = 1)\n",
    "# #                         df3['sample'] = df3['Address'].replace(\" \",'', regex=True)\n",
    "# #                         df3['pincode'] = re.findall('\\d+', str(df3['sample']))[-1]\n",
    "# #                         df4 = df3.drop([\"sample\"], axis = 1)\n",
    "# #                         print(df4)\n",
    "# #                         time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "473fcc02",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
